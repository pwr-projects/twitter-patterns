{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "import copy\n",
    "\n",
    "import emoji\n",
    "from IPython.display import display, HTML\n",
    "import nltk\n",
    "import numpy as np\n",
    "from tqdm._tqdm_notebook import tqdm_notebook as tqdm\n",
    "import pandas as pd\n",
    "from polyglot.text import Text\n",
    "\n",
    "import _utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tweets_file = '../tweets/actors/tweets.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(sample_tweets_file, low_memory=False)\n",
    "# raw_df = pd.read_csv(sample_tweets_file, low_memory=False)\n",
    "# df = copy.deepcopy(raw_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = 'actors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner = utils.TweetCleaner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tmp_clean_tweet'] = df.progress_apply(lambda tweet: cleaner.clean(tweet.tweet), axis=1)\n",
    "df['tmp_clean_tweet_without_emojis'] = df.progress_apply(\n",
    "    lambda tweet: [word for word in tweet.tmp_clean_tweet if word not in emoji.UNICODE_EMOJI], axis=1)\n",
    "\n",
    "df['tp_group'] = group\n",
    "df['tp_author'] = df.progress_apply(lambda tweet: tweet.username, axis=1)\n",
    "df['tp_date'] = df.progress_apply(lambda tweet: tweet.date, axis=1)\n",
    "df['tp_time'] = df.progress_apply(lambda tweet: tweet.time, axis=1)\n",
    "\n",
    "df['tp_tweet'] = df.progress_apply(lambda tweet: tweet.tweet, axis=1)\n",
    "df['tp_clean_tweet'] = df.progress_apply(lambda tweet: ' '.join(tweet.tmp_clean_tweet_without_emojis), axis=1)\n",
    "\n",
    "df['tp_clean_tweet_words_num'] = df.progress_apply(lambda tweet: len(tweet.tmp_clean_tweet_without_emojis), axis=1)\n",
    "df['tp_clean_tweet_len'] = df.progress_apply(lambda tweet: len(tweet.tp_clean_tweet), axis=1)\n",
    "\n",
    "df['tp_sentiment'] = df.progress_apply(\n",
    "    lambda tweet: np.mean([word.polarity for word in Text(' '.join(tweet.tmp_clean_tweet_without_emojis),\n",
    "                                                          hint_language_code='en').words]) \n",
    "    if tweet.tmp_clean_tweet_without_emojis else 0, axis=1)  # polyglot can't handle strings passed explicitly :O\n",
    "\n",
    "df['tp_emojis_num'] = df.progress_apply(lambda tweet: len([word for word in tweet.tmp_clean_tweet \n",
    "                                                       if word in emoji.UNICODE_EMOJI]), axis=1)\n",
    "df['tp_mentions_num'] = df.progress_apply(lambda tweet: len(literal_eval(tweet.mentions)), axis=1)\n",
    "df['tp_hashtags_num'] = df.progress_apply(lambda tweet: len(literal_eval(tweet.tags)), axis=1)\n",
    "\n",
    "df['tp_has_url'] = df.progress_apply(lambda tweet: bool(len(literal_eval(tweet.urls))), axis=1)\n",
    "df['tp_has_image'] = df.progress_apply(lambda tweet: bool(len(literal_eval(tweet.photos))), axis=1)\n",
    "\n",
    "df['tp_has_gif'] = df.progress_apply(lambda tweet: not pd.isnull(tweet.gif_url), axis=1)\n",
    "df['tp_has_video'] = df.progress_apply(lambda tweet: not pd.isnull(tweet.video_url), axis=1)\n",
    "df['tp_has_place'] = df.progress_apply(lambda tweet: not pd.isnull(tweet.place), axis=1)\n",
    "\n",
    "df['tp_replies_count'] = df.progress_apply(lambda tweet: tweet.replies_count, axis=1)\n",
    "df['tp_retweets_count'] = df.progress_apply(lambda tweet: tweet.retweets_count, axis=1)\n",
    "df['tp_likes_count'] = df.progress_apply(lambda tweet: tweet.likes_count, axis=1)\n",
    "\n",
    "df['tp_is_reply'] = df.progress_apply(lambda tweet: bool(tweet.is_reply_to), axis=1)\n",
    "df['tp_is_quote'] = df.progress_apply(lambda tweet: bool(tweet.is_quote_status), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_rm = [c for c in df.columns if not c.startswith('tp_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = df.drop(cols_to_rm, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', 500, 'display.max_columns', 50, 'display.max_colwidth', -1):\n",
    "    display(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '{group}_tweets.csv'.format(group=group)\n",
    "final_df.to_csv(filename, sep=',', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
